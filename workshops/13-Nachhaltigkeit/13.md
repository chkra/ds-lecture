---
title: "Workshop 13: Nachhaltigkeit"
layout: single
header:
  overlay_color: "#5e616c"
  overlay_image: /assets/images/mm-home-page-feature.jpg
author_profile: true
author: Christina Kratsch
lecture_name: "Data Science"
lecture_desc: "Grundlegende Methoden fÃ¼r die Exploration und das Management von Daten."
licence: "CC-BY"
licence_desc: 2024 | HTW Berlin 
classes: wide
---


### ğŸš€ Fallstudie

**Stellen Sie sich vor**: Sie sind Senior Data Scientist Berater in einem IT-Beratungsunternehmen. Ein langjÃ¤hriger Kunde, die Pfefferminzia Krankenversicherung, spricht Sie an: erstellen Sie aus den Smart Watch Daten unsere Versicherungskunden eine KI fÃ¼r Diabetes-Patienten, die bei besorgniserregenden Entwicklungen warnt. Unsere Versicherungskunden mit Diabetes, die am Programm SmartHealth+ teilnehmen, erhalten am Ende des Jahres eine VersicherungsprÃ¤mie.
{: .notice--warning} 

**Was denken Sie?**
- Sollte man das Ã¼berhaupt machen?
- Welche Fehler haben die Daten vermutlich?
- Wie kann der Code auditiert werden?
- Welche Accuracy haben einfache, regelbasierte AnsÃ¤tze?
- Welche Strukturen gibt es im Prozess, um Fehler und Beschwerden zu bestimmen und einzubauen?
- Wie divers ist das Team, dass das System baut?
- Welche Fehlerraten haben die unterschiedlichen Untergruppen?


### ğŸ—£ Talk: AI Diversity

Folgen Sie dem Vortrag der Expertin. Was sind Ihre eigenen Gedanken dazu?

**Aufgabe**: Ãœberlegen Sie, ob / wie der Aspekt AI Diversity *oder* Data Bias in Ihrer eigenene Data Science Projektarbeit relevant ist und wie Sie das Thema behandelt haben. Vielleicht kÃ¶nnen Sie die Fragen aus der Fallstudie oben auf Ihre eigene Arbeit anwenden? **Wenn mÃ¶glich, gehen Sie kurz in Ihrem Video darauf ein oder fÃ¼gen Sie eine Dokumentationszelle in Ihr begleitendes Jupyter Notebook ein.**
{: .notice--warning} 